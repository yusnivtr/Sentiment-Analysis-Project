{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tải dataset vào cache của kagglehub...\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.10).\n",
      "Dataset đã được tải về cache tại: /home/tiamo/.cache/kagglehub/datasets/jp797498e/twitter-entity-sentiment-analysis/versions/2\n",
      "Đang di chuyển tệp từ cache vào thư mục '/home/tiamo/Documents/code/NLP/Sentiment-Analysis-Project/data'...\n",
      "Hoàn tất! Dữ liệu đã được chuyển đến: /home/tiamo/Documents/code/NLP/Sentiment-Analysis-Project/data\n",
      "Các tệp trong thư mục '/home/tiamo/Documents/code/NLP/Sentiment-Analysis-Project/data':\n",
      "- twitter_validation.csv\n",
      "- twitter_training.csv.zip\n",
      "- twitter_training.csv\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "target_folder = \"/home/tiamo/Documents/code/NLP/Sentiment-Analysis-Project/data\"\n",
    "\n",
    "os.makedirs(target_folder, exist_ok=True) \n",
    "\n",
    "print(\"Đang tải dataset vào cache của kagglehub...\")\n",
    "try:\n",
    "    cache_path = kagglehub.dataset_download(\"jp797498e/twitter-entity-sentiment-analysis\")\n",
    "    print(f\"Dataset đã được tải về cache tại: {cache_path}\")\n",
    "\n",
    "    print(f\"Đang di chuyển tệp từ cache vào thư mục '{target_folder}'...\")\n",
    "\n",
    "    for item_name in os.listdir(cache_path):\n",
    "        source_item = os.path.join(cache_path, item_name)\n",
    "        print(f\"Soucre item: {source_item}\")\n",
    "        destination_item = os.path.join(target_folder, item_name)\n",
    "\n",
    "        if os.path.exists(destination_item):\n",
    "            if os.path.isdir(destination_item):\n",
    "                shutil.rmtree(destination_item)\n",
    "            else:\n",
    "                os.remove(destination_item)\n",
    "\n",
    "        shutil.move(source_item, destination_item)\n",
    "\n",
    "\n",
    "    print(f\"Hoàn tất! Dữ liệu đã được chuyển đến: {os.path.abspath(target_folder)}\")\n",
    "    print(f\"Các tệp trong thư mục '{target_folder}':\")\n",
    "    for item in os.listdir(target_folder):\n",
    "        print(f\"- {item}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Đã xảy ra lỗi: {e}\")\n",
    "    print(\"Vui lòng kiểm tra kết nối mạng và xác thực Kaggle của bạn.\")\n",
    "    print(\"Hãy chắc chắn bạn đã đặt file kaggle.json hoặc dùng kagglehub.login().\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting into borderlands and i can murder y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74676</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that the Windows partition of my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74677</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that my Mac window partition is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74678</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized the windows partition of my Mac ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74679</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized between the windows partition of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74680</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just like the windows partition of my Mac is l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74681 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          label                                               text\n",
       "0      Positive  I am coming to the borders and I will kill you...\n",
       "1      Positive  im getting on borderlands and i will kill you ...\n",
       "2      Positive  im coming on borderlands and i will murder you...\n",
       "3      Positive  im getting on borderlands 2 and i will murder ...\n",
       "4      Positive  im getting into borderlands and i can murder y...\n",
       "...         ...                                                ...\n",
       "74676  Positive  Just realized that the Windows partition of my...\n",
       "74677  Positive  Just realized that my Mac window partition is ...\n",
       "74678  Positive  Just realized the windows partition of my Mac ...\n",
       "74679  Positive  Just realized between the windows partition of...\n",
       "74680  Positive  Just like the windows partition of my Mac is l...\n",
       "\n",
       "[74681 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "path = os.path.join(os.getcwd(),'data/twitter_training.csv')\n",
    "header = ['label','text']\n",
    "df = pd.read_csv(path)\n",
    "df = df.iloc[:,2:4]\n",
    "df.columns = header\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Negative      22542\n",
       "Positive      20831\n",
       "Neutral       18318\n",
       "Irrelevant    12990\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kagglehub\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "class TwitterDataset:\n",
    "    def __init__(self,file_path):\n",
    "        self.file_path = file_path\n",
    "        self.df = None\n",
    "        \n",
    "    def download_data(self):\n",
    "        data = pd.read_csv(os.path.join(os.getcwd(),self.file_path))\n",
    "        header = ['label','text']\n",
    "        self.df = pd.DataFrame(data.iloc[:,2:4])\n",
    "        self.df.columns = header\n",
    "        \n",
    "    def prepocess_data(self):\n",
    "        pass\n",
    "    \n",
    "twitter = TwitterDataset('data/twitter_training.csv')\n",
    "twitter.download_data()\n",
    "twitter.df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2876820724517808"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "sentences = [\n",
    "    \"machine learning is great\",\n",
    "    \"natural language processing and machine learning are fun\",\n",
    "    \"gensim is a useful library for text processing\"\n",
    "]\n",
    "\n",
    "processed_sentences = [simple_preprocess(sentence) for sentence in sentences]\n",
    "\n",
    "vectorizer = TfidfVectorizer(lowercase=False)\n",
    "\n",
    "vectorizer.fit(sentences)\n",
    "vectorizer.vocabulary_.items()\n",
    "tmp = {word: vectorizer.idf_[i] for word, i in vectorizer.vocabulary_.items()}\n",
    "tmp.get('machine')\n",
    "\n",
    "\n",
    "\n",
    "# model = Word2Vec(sentences=processed_sentences, vector_size=100, window=5, min_count=1, workers=4,epochs=20)\n",
    "\n",
    "vector = model.wv['machine']  \n",
    "similar_words = model.wv.most_similar('machine') \n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Word2Vec for 10 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiamo/.local/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataLoader import TwitterDataset\n",
    "from processor import TextProcessor\n",
    "from model.tfidf_model import TfIdfModel\n",
    "from model.word2vec import Word2VecMLP\n",
    "from nltk import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "train_loader = TwitterDataset('data/twitter_training.csv')\n",
    "train_loader.load_data()\n",
    "train_loader.prepocess_label()\n",
    "df_train = train_loader.df\n",
    "\n",
    "test_loader = TwitterDataset('data/twitter_validation.csv')\n",
    "test_loader.load_data()\n",
    "test_loader.prepocess_label()\n",
    "df_test = test_loader.df\n",
    "\n",
    "\n",
    "preprocessor = TextProcessor()\n",
    "df_train,df_test = preprocessor.preproces_dataframe(df_train),preprocessor.preproces_dataframe(df_test)\n",
    "\n",
    "# TFIDF - Model\n",
    "# tfidf_model = TfIdfModel()\n",
    "# tfidf_model.train(df_train['clean text'],df_train['label'])\n",
    "# tfidf_model.evaluate(df_test['clean text'],df_test['label'])\n",
    "\n",
    "\n",
    "df_train[\"tokenized\"] = df_train[\"clean text\"].apply(lambda x: word_tokenize(x.lower()))\n",
    "df_test['tokenized'] = df_test['clean text'].apply(lambda x: word_tokenize(x.lower()))\n",
    "\n",
    "X_train,y_train = df_train['tokenized'].tolist(),df_train['label'].tolist()\n",
    "X_test,y_test = df_test['tokenized'].tolist(),df_test['label'].tolist()\n",
    "\n",
    "# X_train,y_train = np.array(X_train,dtype=np.float32),np.array(y_train,dtype=np.float32)\n",
    "# X_test,y_test = np.array(X_test,dtype=np.float32),np.array(y_test,dtype=np.float32)\n",
    "\n",
    "\n",
    "word2vec_mlp = Word2VecMLP(mlp_epochs=100,word2vec_epochs=10)\n",
    "word2vec_mlp.train_word2vec(X_train)\n",
    "tfidf_weights = word2vec_mlp.compute_tfidf_weights(X_train)\n",
    "\n",
    "print(word2vec_mlp.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLP\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "055ce3c7598644d098de7e4e6cfc6dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.3948\n",
      "Epoch [11/100], Loss: 1.1342\n",
      "Epoch [21/100], Loss: 1.0858\n",
      "Epoch [31/100], Loss: 1.0549\n",
      "Epoch [41/100], Loss: 1.0274\n",
      "Epoch [51/100], Loss: 0.9995\n",
      "Epoch [61/100], Loss: 0.9717\n",
      "Epoch [71/100], Loss: 0.9494\n",
      "Epoch [81/100], Loss: 0.9250\n",
      "Epoch [91/100], Loss: 0.8982\n",
      "TF-IDF Weighted Word2Vec + MLP Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.77      0.70       266\n",
      "           1       0.67      0.78      0.72       276\n",
      "           2       0.67      0.60      0.63       285\n",
      "           3       0.69      0.42      0.52       171\n",
      "\n",
      "    accuracy                           0.66       998\n",
      "   macro avg       0.67      0.64      0.64       998\n",
      "weighted avg       0.67      0.66      0.66       998\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6643286573146293"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_mlp.train(X_train,y_train,tfidf_weights)\n",
    "word2vec_mlp.evaluate(X_test,y_test,tfidf_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2454, 0.6158, 0.0849, 0.0254, 0.0285],\n",
       "        [0.3026, 0.4419, 0.0476, 0.1130, 0.0949],\n",
       "        [0.2641, 0.1971, 0.4325, 0.0186, 0.0877]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
